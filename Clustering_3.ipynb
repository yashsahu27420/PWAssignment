{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5klZJO0x70bw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "ce0c8920-6eff-47df-820c-1034f10c7989"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nClustering is a fundamental concept in data analysis and machine learning that involves grouping similar data points together based on their inherent characteristics or features. The primary objective of clustering is to discover patterns, structures, or natural groupings within a dataset without prior knowledge of the class labels. Here's a basic explanation of the concept of clustering:\\n\\n1. **Basic Concept**:\\n   - **Grouping Similar Data**: Clustering aims to partition a dataset into clusters or groups where data points within the same cluster are more similar to each other than to those in other clusters.\\n   - **Unsupervised Learning**: Unlike supervised learning, clustering is an unsupervised learning technique, meaning it doesn't require labeled data for training. Instead, it identifies patterns based solely on the data's inherent structure.\\n\\n2. **Examples of Applications**:\\n\\n   a. **Customer Segmentation**:\\n      - In marketing, clustering can be used to segment customers into groups based on their purchasing behavior, demographics, or preferences. This helps businesses tailor marketing strategies to specific customer segments.\\n\\n   b. **Image Segmentation**:\\n      - In computer vision, clustering can be used to segment images into regions with similar characteristics. For example, it can be applied to separate foreground objects from the background.\\n\\n   c. **Anomaly Detection**:\\n      - Clustering can be used to detect anomalies or outliers in datasets. By clustering normal data points together, any data points that do not fit into these clusters can be considered anomalies.\\n\\n   d. **Document Clustering**:\\n      - Text documents can be clustered based on the similarity of their content. This is useful in information retrieval, topic modeling, and organizing large document collections.\\n\\n   e. **Genomic Data Analysis**:\\n      - In bioinformatics, clustering can be applied to group genes or proteins with similar functions, expression patterns, or sequences, aiding in the understanding of genetic relationships.\\n\\n   f. **Recommendation Systems**:\\n      - Clustering can be used to group users or items with similar characteristics in recommendation systems. This helps in providing personalized recommendations to users based on the preferences of similar users.\\n\\n   g. **Network Analysis**:\\n      - Clustering can be used to identify communities or groups within a network, such as social networks or communication networks. This can be valuable for understanding network structures.\\n\\n   h. **Market Segmentation**:\\n      - Businesses can use clustering to segment markets based on geographic, demographic, or psychographic factors to tailor their products or services to different market segments.\\n\\n   i. **Image Compression**:\\n      - In image processing, clustering techniques like K-means can be used for image compression by grouping similar pixel values together, reducing the storage space required.\\n\\n   j. **Fraud Detection**:\\n      - In finance, clustering can be used to identify patterns of fraudulent transactions by clustering transactions with similar characteristics.\\n\\nThese are just a few examples of the many applications of clustering in various domains. Clustering is a versatile tool for exploratory data analysis, pattern recognition, and decision-making in fields where understanding data relationships and structures is crucial.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Q1. Explain the basic concept of clustering and give examples of applications where clustering is useful.\n",
        "\n",
        "'''\n",
        "Clustering is a fundamental concept in data analysis and machine learning that involves grouping similar data points together based on their inherent characteristics or features. The primary objective of clustering is to discover patterns, structures, or natural groupings within a dataset without prior knowledge of the class labels. Here's a basic explanation of the concept of clustering:\n",
        "\n",
        "1. **Basic Concept**:\n",
        "   - **Grouping Similar Data**: Clustering aims to partition a dataset into clusters or groups where data points within the same cluster are more similar to each other than to those in other clusters.\n",
        "   - **Unsupervised Learning**: Unlike supervised learning, clustering is an unsupervised learning technique, meaning it doesn't require labeled data for training. Instead, it identifies patterns based solely on the data's inherent structure.\n",
        "\n",
        "2. **Examples of Applications**:\n",
        "\n",
        "   a. **Customer Segmentation**:\n",
        "      - In marketing, clustering can be used to segment customers into groups based on their purchasing behavior, demographics, or preferences. This helps businesses tailor marketing strategies to specific customer segments.\n",
        "\n",
        "   b. **Image Segmentation**:\n",
        "      - In computer vision, clustering can be used to segment images into regions with similar characteristics. For example, it can be applied to separate foreground objects from the background.\n",
        "\n",
        "   c. **Anomaly Detection**:\n",
        "      - Clustering can be used to detect anomalies or outliers in datasets. By clustering normal data points together, any data points that do not fit into these clusters can be considered anomalies.\n",
        "\n",
        "   d. **Document Clustering**:\n",
        "      - Text documents can be clustered based on the similarity of their content. This is useful in information retrieval, topic modeling, and organizing large document collections.\n",
        "\n",
        "   e. **Genomic Data Analysis**:\n",
        "      - In bioinformatics, clustering can be applied to group genes or proteins with similar functions, expression patterns, or sequences, aiding in the understanding of genetic relationships.\n",
        "\n",
        "   f. **Recommendation Systems**:\n",
        "      - Clustering can be used to group users or items with similar characteristics in recommendation systems. This helps in providing personalized recommendations to users based on the preferences of similar users.\n",
        "\n",
        "   g. **Network Analysis**:\n",
        "      - Clustering can be used to identify communities or groups within a network, such as social networks or communication networks. This can be valuable for understanding network structures.\n",
        "\n",
        "   h. **Market Segmentation**:\n",
        "      - Businesses can use clustering to segment markets based on geographic, demographic, or psychographic factors to tailor their products or services to different market segments.\n",
        "\n",
        "   i. **Image Compression**:\n",
        "      - In image processing, clustering techniques like K-means can be used for image compression by grouping similar pixel values together, reducing the storage space required.\n",
        "\n",
        "   j. **Fraud Detection**:\n",
        "      - In finance, clustering can be used to identify patterns of fraudulent transactions by clustering transactions with similar characteristics.\n",
        "\n",
        "These are just a few examples of the many applications of clustering in various domains. Clustering is a versatile tool for exploratory data analysis, pattern recognition, and decision-making in fields where understanding data relationships and structures is crucial.'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2. What is DBSCAN and how does it differ from other clustering algorithms such as k-means and hierarchical clustering?\n",
        "\n",
        "'''\n",
        "\n",
        "DBSCAN, which stands for Density-Based Spatial Clustering of Applications with Noise, is a popular clustering algorithm used in machine learning and data analysis. It differs from other clustering algorithms like K-means and hierarchical clustering in several key ways:\n",
        "\n",
        "1. **Density-Based Clustering**:\n",
        "   - DBSCAN is a density-based clustering algorithm. Instead of assuming that clusters have a spherical or globular shape (as K-means does) or forming clusters based on a hierarchical structure (as hierarchical clustering does), DBSCAN defines clusters as regions of high data point density separated by regions of low data point density.\n",
        "\n",
        "2. **No Assumption of Cluster Shape**:\n",
        "   - K-means assumes that clusters are spherical and tries to find the cluster centers and assign data points to the nearest center. In contrast, DBSCAN can discover clusters of arbitrary shapes, making it more versatile for various types of datasets.\n",
        "\n",
        "3. **Variable Cluster Sizes**:\n",
        "   - DBSCAN can identify clusters with varying shapes and sizes because it doesn't rely on preset cluster centers. This allows it to handle clusters of different densities effectively.\n",
        "\n",
        "4. **Noise Tolerance**:\n",
        "   - DBSCAN can identify and label outliers or noise in the dataset as points that do not belong to any cluster. K-means typically assigns all data points to clusters, even if some data points do not belong to any meaningful cluster.\n",
        "\n",
        "5. **Number of Clusters Not Required**:\n",
        "   - DBSCAN does not require specifying the number of clusters in advance, which is a common requirement in K-means and hierarchical clustering. DBSCAN discovers clusters based on density and connectivity, so it adapts to the data's inherent structure.\n",
        "\n",
        "6. **Hierarchical Nature**:\n",
        "   - Hierarchical clustering builds a tree-like structure (dendrogram) that represents the hierarchy of clusters at different levels of granularity. DBSCAN does not provide such a hierarchy; it directly identifies clusters and noise points in a flat manner.\n",
        "\n",
        "7. **Handling Uneven Density**:\n",
        "   - DBSCAN can effectively handle datasets with clusters of varying densities. It can differentiate between densely packed regions and sparsely populated regions, automatically adjusting the cluster boundaries accordingly.\n",
        "\n",
        "8. **Parameter Sensitivity**:\n",
        "   - DBSCAN has two main hyperparameters: the \"eps\" parameter, which defines the radius around a data point within which other points are considered neighbors, and the \"min_samples\" parameter, which specifies the minimum number of points required to form a dense region (cluster). The choice of these parameters can impact the clustering results, and selecting appropriate values can be a bit challenging.\n",
        "\n",
        "In summary, DBSCAN is a density-based clustering algorithm that excels at finding clusters of arbitrary shapes, handling varying cluster sizes and densities, and identifying noise or outliers. It is particularly useful when the number of clusters is unknown or when clusters have complex shapes. However, it does require careful parameter tuning, and its performance can be affected by the choice of parameters.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "iybWHwZsw-oi",
        "outputId": "8a05832c-1eda-47d7-e534-328504c7cf43"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nDBSCAN, which stands for Density-Based Spatial Clustering of Applications with Noise, is a popular clustering algorithm used in machine learning and data analysis. It differs from other clustering algorithms like K-means and hierarchical clustering in several key ways:\\n\\n1. **Density-Based Clustering**:\\n   - DBSCAN is a density-based clustering algorithm. Instead of assuming that clusters have a spherical or globular shape (as K-means does) or forming clusters based on a hierarchical structure (as hierarchical clustering does), DBSCAN defines clusters as regions of high data point density separated by regions of low data point density.\\n\\n2. **No Assumption of Cluster Shape**:\\n   - K-means assumes that clusters are spherical and tries to find the cluster centers and assign data points to the nearest center. In contrast, DBSCAN can discover clusters of arbitrary shapes, making it more versatile for various types of datasets.\\n\\n3. **Variable Cluster Sizes**:\\n   - DBSCAN can identify clusters with varying shapes and sizes because it doesn\\'t rely on preset cluster centers. This allows it to handle clusters of different densities effectively.\\n\\n4. **Noise Tolerance**:\\n   - DBSCAN can identify and label outliers or noise in the dataset as points that do not belong to any cluster. K-means typically assigns all data points to clusters, even if some data points do not belong to any meaningful cluster.\\n\\n5. **Number of Clusters Not Required**:\\n   - DBSCAN does not require specifying the number of clusters in advance, which is a common requirement in K-means and hierarchical clustering. DBSCAN discovers clusters based on density and connectivity, so it adapts to the data\\'s inherent structure.\\n\\n6. **Hierarchical Nature**:\\n   - Hierarchical clustering builds a tree-like structure (dendrogram) that represents the hierarchy of clusters at different levels of granularity. DBSCAN does not provide such a hierarchy; it directly identifies clusters and noise points in a flat manner.\\n\\n7. **Handling Uneven Density**:\\n   - DBSCAN can effectively handle datasets with clusters of varying densities. It can differentiate between densely packed regions and sparsely populated regions, automatically adjusting the cluster boundaries accordingly.\\n\\n8. **Parameter Sensitivity**:\\n   - DBSCAN has two main hyperparameters: the \"eps\" parameter, which defines the radius around a data point within which other points are considered neighbors, and the \"min_samples\" parameter, which specifies the minimum number of points required to form a dense region (cluster). The choice of these parameters can impact the clustering results, and selecting appropriate values can be a bit challenging.\\n\\nIn summary, DBSCAN is a density-based clustering algorithm that excels at finding clusters of arbitrary shapes, handling varying cluster sizes and densities, and identifying noise or outliers. It is particularly useful when the number of clusters is unknown or when clusters have complex shapes. However, it does require careful parameter tuning, and its performance can be affected by the choice of parameters.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3. How do you determine the optimal values for the epsilon and minimum points parameters in DBSCAN clustering?\n",
        "\n",
        "'''\n",
        "Determining the optimal values for the epsilon (ε) and minimum points (MinPts) parameters in DBSCAN can significantly impact the quality of your clustering results. These parameters control the density and size of clusters in DBSCAN. Here are some methods and guidelines for selecting appropriate values:\n",
        "\n",
        "1. **Visual Inspection**:\n",
        "   - One common approach is to perform visual inspection of your data. Plot your data points and explore different values of ε by varying the radius. Observe how the clustering results change as you adjust ε. You can use various visualization tools like scatter plots and density plots to help with this.\n",
        "\n",
        "2. **K-Distance Plot**:\n",
        "   - Calculate the k-distance plot for your data, which involves finding the distance to the k-th nearest neighbor for each data point. Typically, you start with k = MinPts - 1 (or another reasonable value). The point where you observe a significant increase in the distance can be a good estimate for ε. This is known as the \"knee point\" in the plot.\n",
        "\n",
        "3. **Silhouette Score**:\n",
        "   - The silhouette score measures how similar an object is to its cluster compared to other clusters. You can compute the silhouette score for different combinations of ε and MinPts to find the combination that maximizes the silhouette score. A higher silhouette score indicates better cluster separation.\n",
        "\n",
        "4. **DBSCAN Variants**:\n",
        "   - Some variations of DBSCAN, such as OPTICS (Ordering Points To Identify Cluster Structure), automatically estimate ε based on the data's density characteristics. OPTICS can be a useful alternative if you want to avoid manual parameter tuning.\n",
        "\n",
        "5. **Domain Knowledge**:\n",
        "   - Sometimes, domain knowledge can provide insights into reasonable parameter choices. If you have prior information about the expected cluster sizes or the density of data points, it can guide your parameter selection.\n",
        "\n",
        "6. **Grid Search**:\n",
        "   - You can perform a grid search by trying multiple combinations of ε and MinPts over a predefined range. Use a validation metric (e.g., silhouette score or Davies-Bouldin index) to evaluate the quality of clustering for each combination and select the one that yields the best result.\n",
        "\n",
        "7. **Incremental Adjustment**:\n",
        "   - Start with a broad range of parameter values and gradually narrow it down based on the quality of clustering results. This iterative approach can help you find optimal parameters.\n",
        "\n",
        "8. **Trial and Error**:\n",
        "   - In practice, selecting optimal parameters often involves some trial and error. Experiment with different values, observe the resulting clusters, and adjust the parameters until you achieve meaningful and stable clustering.\n",
        "\n",
        "Remember that there is no one-size-fits-all solution for ε and MinPts. The choice of parameters depends on the specific characteristics of your dataset and the goals of your analysis. It's essential to strike a balance between capturing meaningful clusters and avoiding overfitting or underfitting. Additionally, be aware that DBSCAN can produce different results for different parameter values, so it's crucial to validate your clustering results using appropriate evaluation metrics and domain knowledge.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "bobTaJP2xJv2",
        "outputId": "75e64379-f9a4-4cba-928f-581dcc1d265f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nDetermining the optimal values for the epsilon (ε) and minimum points (MinPts) parameters in DBSCAN can significantly impact the quality of your clustering results. These parameters control the density and size of clusters in DBSCAN. Here are some methods and guidelines for selecting appropriate values:\\n\\n1. **Visual Inspection**:\\n   - One common approach is to perform visual inspection of your data. Plot your data points and explore different values of ε by varying the radius. Observe how the clustering results change as you adjust ε. You can use various visualization tools like scatter plots and density plots to help with this.\\n\\n2. **K-Distance Plot**:\\n   - Calculate the k-distance plot for your data, which involves finding the distance to the k-th nearest neighbor for each data point. Typically, you start with k = MinPts - 1 (or another reasonable value). The point where you observe a significant increase in the distance can be a good estimate for ε. This is known as the \"knee point\" in the plot.\\n\\n3. **Silhouette Score**:\\n   - The silhouette score measures how similar an object is to its cluster compared to other clusters. You can compute the silhouette score for different combinations of ε and MinPts to find the combination that maximizes the silhouette score. A higher silhouette score indicates better cluster separation.\\n\\n4. **DBSCAN Variants**:\\n   - Some variations of DBSCAN, such as OPTICS (Ordering Points To Identify Cluster Structure), automatically estimate ε based on the data\\'s density characteristics. OPTICS can be a useful alternative if you want to avoid manual parameter tuning.\\n\\n5. **Domain Knowledge**:\\n   - Sometimes, domain knowledge can provide insights into reasonable parameter choices. If you have prior information about the expected cluster sizes or the density of data points, it can guide your parameter selection.\\n\\n6. **Grid Search**:\\n   - You can perform a grid search by trying multiple combinations of ε and MinPts over a predefined range. Use a validation metric (e.g., silhouette score or Davies-Bouldin index) to evaluate the quality of clustering for each combination and select the one that yields the best result.\\n\\n7. **Incremental Adjustment**:\\n   - Start with a broad range of parameter values and gradually narrow it down based on the quality of clustering results. This iterative approach can help you find optimal parameters.\\n\\n8. **Trial and Error**:\\n   - In practice, selecting optimal parameters often involves some trial and error. Experiment with different values, observe the resulting clusters, and adjust the parameters until you achieve meaningful and stable clustering.\\n\\nRemember that there is no one-size-fits-all solution for ε and MinPts. The choice of parameters depends on the specific characteristics of your dataset and the goals of your analysis. It\\'s essential to strike a balance between capturing meaningful clusters and avoiding overfitting or underfitting. Additionally, be aware that DBSCAN can produce different results for different parameter values, so it\\'s crucial to validate your clustering results using appropriate evaluation metrics and domain knowledge.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4. How does DBSCAN clustering handle outliers in a dataset?\n",
        "\n",
        "'''\n",
        "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) clustering handles outliers in a dataset in a natural and effective way. It identifies and labels outliers as noise points during the clustering process. Here's how DBSCAN deals with outliers:\n",
        "\n",
        "1. **Density-Based Criterion**:\n",
        "   - DBSCAN defines clusters as dense regions of data points that are separated by areas of lower point density. It does this by considering two key parameters: ε (epsilon) and MinPts (minimum points). A point is considered a core point if there are at least MinPts data points within a distance of ε from it. Core points are at the center of clusters.\n",
        "\n",
        "2. **Classification of Points**:\n",
        "   - DBSCAN classifies data points into three categories:\n",
        "     a. Core Points: These are data points that have at least MinPts neighbors within ε distance. They are part of a cluster.\n",
        "     b. Border Points: Border points have fewer than MinPts neighbors within ε distance but are within ε distance of a core point. They are considered part of the cluster associated with the core point.\n",
        "     c. Noise Points (Outliers): Noise points do not meet the criteria for being core or border points. They are not assigned to any cluster and are labeled as outliers.\n",
        "\n",
        "3. **Cluster Formation**:\n",
        "   - DBSCAN starts by randomly selecting an unvisited data point. If the selected point is a core point, a new cluster is created, and all reachable data points (core or border) are assigned to that cluster. This process continues iteratively until no more core points can be reached. Border points are included in clusters but are not used to expand clusters further.\n",
        "\n",
        "4. **Handling Outliers**:\n",
        "   - Noise points, by definition, are not assigned to any cluster. These points are essentially treated as outliers or data that does not belong to any meaningful cluster. DBSCAN's ability to identify and isolate noise points makes it robust in handling datasets with outliers.\n",
        "\n",
        "Advantages of DBSCAN's handling of outliers:\n",
        "\n",
        "- Outliers do not disrupt the formation of clusters: DBSCAN does not force outliers into any cluster. Instead, it focuses on identifying dense regions and isolating noise points from clusters.\n",
        "- No need for explicit removal: Unlike some other clustering methods, which may require you to pre-process or remove outliers before clustering, DBSCAN identifies them during the clustering process.\n",
        "- Robust to varying cluster densities: DBSCAN can handle datasets with clusters of varying sizes and shapes without falsely labeling some clusters as outliers or merging separate clusters due to the presence of outliers.\n",
        "\n",
        "However, it's important to note that the effectiveness of DBSCAN in handling outliers depends on appropriate parameter tuning, particularly setting the values for ε and MinPts correctly. If these parameters are not chosen carefully, DBSCAN may either classify too many points as noise (underfitting) or include outliers within clusters (overfitting). Therefore, parameter selection is crucial for achieving meaningful clustering results, especially when dealing with datasets that contain a substantial number of outliers.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "HaxJ2KmexY0u",
        "outputId": "c0896542-938c-4bbe-f520-cf4bf66e6919"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nDBSCAN (Density-Based Spatial Clustering of Applications with Noise) clustering handles outliers in a dataset in a natural and effective way. It identifies and labels outliers as noise points during the clustering process. Here's how DBSCAN deals with outliers:\\n\\n1. **Density-Based Criterion**:\\n   - DBSCAN defines clusters as dense regions of data points that are separated by areas of lower point density. It does this by considering two key parameters: ε (epsilon) and MinPts (minimum points). A point is considered a core point if there are at least MinPts data points within a distance of ε from it. Core points are at the center of clusters.\\n\\n2. **Classification of Points**:\\n   - DBSCAN classifies data points into three categories:\\n     a. Core Points: These are data points that have at least MinPts neighbors within ε distance. They are part of a cluster.\\n     b. Border Points: Border points have fewer than MinPts neighbors within ε distance but are within ε distance of a core point. They are considered part of the cluster associated with the core point.\\n     c. Noise Points (Outliers): Noise points do not meet the criteria for being core or border points. They are not assigned to any cluster and are labeled as outliers.\\n\\n3. **Cluster Formation**:\\n   - DBSCAN starts by randomly selecting an unvisited data point. If the selected point is a core point, a new cluster is created, and all reachable data points (core or border) are assigned to that cluster. This process continues iteratively until no more core points can be reached. Border points are included in clusters but are not used to expand clusters further.\\n\\n4. **Handling Outliers**:\\n   - Noise points, by definition, are not assigned to any cluster. These points are essentially treated as outliers or data that does not belong to any meaningful cluster. DBSCAN's ability to identify and isolate noise points makes it robust in handling datasets with outliers.\\n\\nAdvantages of DBSCAN's handling of outliers:\\n\\n- Outliers do not disrupt the formation of clusters: DBSCAN does not force outliers into any cluster. Instead, it focuses on identifying dense regions and isolating noise points from clusters.\\n- No need for explicit removal: Unlike some other clustering methods, which may require you to pre-process or remove outliers before clustering, DBSCAN identifies them during the clustering process.\\n- Robust to varying cluster densities: DBSCAN can handle datasets with clusters of varying sizes and shapes without falsely labeling some clusters as outliers or merging separate clusters due to the presence of outliers.\\n\\nHowever, it's important to note that the effectiveness of DBSCAN in handling outliers depends on appropriate parameter tuning, particularly setting the values for ε and MinPts correctly. If these parameters are not chosen carefully, DBSCAN may either classify too many points as noise (underfitting) or include outliers within clusters (overfitting). Therefore, parameter selection is crucial for achieving meaningful clustering results, especially when dealing with datasets that contain a substantial number of outliers.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5. How does DBSCAN clustering differ from k-means clustering?\n",
        "\n",
        "'''\n",
        "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) clustering and K-means clustering are two distinct clustering algorithms that differ in their approach, characteristics, and use cases. Here are the key differences between DBSCAN and K-means clustering:\n",
        "\n",
        "1. **Clustering Approach**:\n",
        "\n",
        "   - **DBSCAN**:\n",
        "     - DBSCAN is a density-based clustering algorithm. It identifies clusters based on the density of data points. It groups data points that are close to each other and separates regions of high density from regions of low density.\n",
        "     - It does not make any assumptions about the shape or size of clusters, making it suitable for discovering clusters of arbitrary shapes.\n",
        "\n",
        "   - **K-means**:\n",
        "     - K-means is a centroid-based clustering algorithm. It forms clusters by finding the center (centroid) of each cluster and assigning data points to the nearest centroid. It assumes that clusters are spherical and have roughly equal sizes.\n",
        "\n",
        "2. **Cluster Shape**:\n",
        "\n",
        "   - **DBSCAN**:\n",
        "     - DBSCAN can discover clusters of arbitrary shapes, including irregular, elongated, or non-convex clusters. It is not limited by the spherical shape assumption.\n",
        "\n",
        "   - **K-means**:\n",
        "     - K-means tends to produce clusters that are spherical or globular in shape. It may not perform well when clusters have non-spherical shapes.\n",
        "\n",
        "3. **Number of Clusters**:\n",
        "\n",
        "   - **DBSCAN**:\n",
        "     - DBSCAN does not require you to specify the number of clusters in advance. It automatically determines the number of clusters based on the density of the data.\n",
        "\n",
        "   - **K-means**:\n",
        "     - K-means requires you to specify the number of clusters (K) before clustering. Choosing the right K value can be a challenging task and may affect the quality of the clustering results.\n",
        "\n",
        "4. **Handling Outliers**:\n",
        "\n",
        "   - **DBSCAN**:\n",
        "     - DBSCAN naturally handles outliers by classifying them as noise points. Outliers do not belong to any cluster in DBSCAN.\n",
        "\n",
        "   - **K-means**:\n",
        "     - K-means assigns all data points to one of the K clusters, which means that outliers will be assigned to the nearest cluster, even if they do not belong to any meaningful cluster. This can lead to poor clustering results when dealing with datasets containing outliers.\n",
        "\n",
        "5. **Initialization**:\n",
        "\n",
        "   - **DBSCAN**:\n",
        "     - DBSCAN does not require an explicit initialization step. It starts by selecting an arbitrary unvisited data point and expands clusters from there.\n",
        "\n",
        "   - **K-means**:\n",
        "     - K-means requires an initial guess for the cluster centroids, which can influence the final clustering results. The choice of initial centroids can impact the algorithm's convergence and the quality of clustering.\n",
        "\n",
        "6. **Parameter Sensitivity**:\n",
        "\n",
        "   - **DBSCAN**:\n",
        "     - DBSCAN has two main hyperparameters: ε (epsilon) and MinPts, which control the density and granularity of clusters. Selecting appropriate values for these parameters can be a challenge.\n",
        "\n",
        "   - **K-means**:\n",
        "     - K-means also requires selecting the number of clusters (K), and the algorithm's convergence can be sensitive to the initial centroid positions.\n",
        "\n",
        "In summary, DBSCAN and K-means are fundamentally different clustering algorithms. DBSCAN is well-suited for datasets with complex cluster shapes, varying cluster sizes, and the presence of outliers. It is particularly useful when you don't know the number of clusters in advance. On the other hand, K-means is simpler to understand and computationally efficient but makes assumptions about cluster shape and size, and it may not handle outliers well without additional pre-processing. The choice between DBSCAN and K-means depends on the characteristics of your data and your specific clustering goals.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "GOfAK23Qxoye",
        "outputId": "9fe75795-a0c4-4abd-9da4-d6732bf56f61"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nDBSCAN (Density-Based Spatial Clustering of Applications with Noise) clustering and K-means clustering are two distinct clustering algorithms that differ in their approach, characteristics, and use cases. Here are the key differences between DBSCAN and K-means clustering:\\n\\n1. **Clustering Approach**:\\n\\n   - **DBSCAN**:\\n     - DBSCAN is a density-based clustering algorithm. It identifies clusters based on the density of data points. It groups data points that are close to each other and separates regions of high density from regions of low density.\\n     - It does not make any assumptions about the shape or size of clusters, making it suitable for discovering clusters of arbitrary shapes.\\n\\n   - **K-means**:\\n     - K-means is a centroid-based clustering algorithm. It forms clusters by finding the center (centroid) of each cluster and assigning data points to the nearest centroid. It assumes that clusters are spherical and have roughly equal sizes.\\n\\n2. **Cluster Shape**:\\n\\n   - **DBSCAN**:\\n     - DBSCAN can discover clusters of arbitrary shapes, including irregular, elongated, or non-convex clusters. It is not limited by the spherical shape assumption.\\n\\n   - **K-means**:\\n     - K-means tends to produce clusters that are spherical or globular in shape. It may not perform well when clusters have non-spherical shapes.\\n\\n3. **Number of Clusters**:\\n\\n   - **DBSCAN**:\\n     - DBSCAN does not require you to specify the number of clusters in advance. It automatically determines the number of clusters based on the density of the data.\\n\\n   - **K-means**:\\n     - K-means requires you to specify the number of clusters (K) before clustering. Choosing the right K value can be a challenging task and may affect the quality of the clustering results.\\n\\n4. **Handling Outliers**:\\n\\n   - **DBSCAN**:\\n     - DBSCAN naturally handles outliers by classifying them as noise points. Outliers do not belong to any cluster in DBSCAN.\\n\\n   - **K-means**:\\n     - K-means assigns all data points to one of the K clusters, which means that outliers will be assigned to the nearest cluster, even if they do not belong to any meaningful cluster. This can lead to poor clustering results when dealing with datasets containing outliers.\\n\\n5. **Initialization**:\\n\\n   - **DBSCAN**:\\n     - DBSCAN does not require an explicit initialization step. It starts by selecting an arbitrary unvisited data point and expands clusters from there.\\n\\n   - **K-means**:\\n     - K-means requires an initial guess for the cluster centroids, which can influence the final clustering results. The choice of initial centroids can impact the algorithm's convergence and the quality of clustering.\\n\\n6. **Parameter Sensitivity**:\\n\\n   - **DBSCAN**:\\n     - DBSCAN has two main hyperparameters: ε (epsilon) and MinPts, which control the density and granularity of clusters. Selecting appropriate values for these parameters can be a challenge.\\n\\n   - **K-means**:\\n     - K-means also requires selecting the number of clusters (K), and the algorithm's convergence can be sensitive to the initial centroid positions.\\n\\nIn summary, DBSCAN and K-means are fundamentally different clustering algorithms. DBSCAN is well-suited for datasets with complex cluster shapes, varying cluster sizes, and the presence of outliers. It is particularly useful when you don't know the number of clusters in advance. On the other hand, K-means is simpler to understand and computationally efficient but makes assumptions about cluster shape and size, and it may not handle outliers well without additional pre-processing. The choice between DBSCAN and K-means depends on the characteristics of your data and your specific clustering goals.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q6. Can DBSCAN clustering be applied to datasets with high dimensional feature spaces? If so, what are some potential challenges?\n",
        "\n",
        "'''\n",
        "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) can be applied to datasets with high-dimensional feature spaces, but it comes with certain challenges and considerations that should be kept in mind. Here's an overview of how DBSCAN can be used in high-dimensional spaces and the associated challenges:\n",
        "\n",
        "**Applying DBSCAN to High-Dimensional Data**:\n",
        "\n",
        "DBSCAN can be used with high-dimensional data, and its core algorithm remains the same regardless of the dimensionality of the feature space. You can apply DBSCAN to datasets where each data point is represented by a large number of features. However, there are some factors to consider:\n",
        "\n",
        "1. **Curse of Dimensionality**:\n",
        "   - High-dimensional spaces can suffer from the \"curse of dimensionality.\" As the number of dimensions increases, the data points tend to become more sparse, making it challenging to define meaningful densities or distances. This can affect the effectiveness of DBSCAN, as the concept of \"neighborhood\" becomes less intuitive in high-dimensional spaces.\n",
        "\n",
        "2. **Parameter Selection**:\n",
        "   - The choice of parameters in DBSCAN, specifically ε (epsilon) and MinPts (minimum points), becomes more critical in high-dimensional spaces. It can be challenging to determine suitable values for these parameters, as the impact of ε and MinPts on clustering behavior may not be as straightforward as in lower-dimensional spaces.\n",
        "\n",
        "3. **Dimension Reduction**:\n",
        "   - Dimension reduction techniques like Principal Component Analysis (PCA) or t-Distributed Stochastic Neighbor Embedding (t-SNE) can be applied to high-dimensional data before running DBSCAN. Reducing dimensionality can help mitigate some of the challenges associated with high-dimensional data and make DBSCAN more effective.\n",
        "\n",
        "4. **Distance Metric Selection**:\n",
        "   - The choice of distance metric can significantly affect DBSCAN's performance in high-dimensional spaces. Some distance metrics, like Euclidean distance, may become less informative as the number of dimensions increases. Consider using more robust distance metrics designed for high-dimensional data, such as cosine similarity or Mahalanobis distance.\n",
        "\n",
        "5. **Data Preprocessing**:\n",
        "   - Data preprocessing steps such as feature scaling, normalization, and outlier removal become crucial in high-dimensional spaces. Addressing outliers and ensuring that features have similar scales can improve the performance of DBSCAN.\n",
        "\n",
        "6. **Interpretability**:\n",
        "   - Interpreting clusters in high-dimensional spaces can be challenging, as visualizing the clusters becomes difficult. The analysis and interpretation of clustering results may require specialized techniques or domain knowledge.\n",
        "\n",
        "7. **Computational Complexity**:\n",
        "   - DBSCAN's computational complexity can increase in high-dimensional spaces due to the need to compute distances between data points in all dimensions. Depending on the dataset's size and dimensionality, this can lead to increased computation time and memory requirements.\n",
        "\n",
        "In summary, while DBSCAN can be applied to high-dimensional feature spaces, it requires careful consideration of the challenges associated with high dimensionality. Parameter tuning, distance metric selection, dimension reduction, and data preprocessing are essential steps in making DBSCAN effective for high-dimensional data. It's also important to evaluate the quality of clustering results and consider alternative clustering algorithms or techniques if DBSCAN does not perform well in a specific high-dimensional dataset.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "Ucf-HyaOx4se",
        "outputId": "69b66b5f-ec65-4a71-f2d4-a21894687f39"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nDBSCAN (Density-Based Spatial Clustering of Applications with Noise) can be applied to datasets with high-dimensional feature spaces, but it comes with certain challenges and considerations that should be kept in mind. Here\\'s an overview of how DBSCAN can be used in high-dimensional spaces and the associated challenges:\\n\\n**Applying DBSCAN to High-Dimensional Data**:\\n\\nDBSCAN can be used with high-dimensional data, and its core algorithm remains the same regardless of the dimensionality of the feature space. You can apply DBSCAN to datasets where each data point is represented by a large number of features. However, there are some factors to consider:\\n\\n1. **Curse of Dimensionality**:\\n   - High-dimensional spaces can suffer from the \"curse of dimensionality.\" As the number of dimensions increases, the data points tend to become more sparse, making it challenging to define meaningful densities or distances. This can affect the effectiveness of DBSCAN, as the concept of \"neighborhood\" becomes less intuitive in high-dimensional spaces.\\n\\n2. **Parameter Selection**:\\n   - The choice of parameters in DBSCAN, specifically ε (epsilon) and MinPts (minimum points), becomes more critical in high-dimensional spaces. It can be challenging to determine suitable values for these parameters, as the impact of ε and MinPts on clustering behavior may not be as straightforward as in lower-dimensional spaces.\\n\\n3. **Dimension Reduction**:\\n   - Dimension reduction techniques like Principal Component Analysis (PCA) or t-Distributed Stochastic Neighbor Embedding (t-SNE) can be applied to high-dimensional data before running DBSCAN. Reducing dimensionality can help mitigate some of the challenges associated with high-dimensional data and make DBSCAN more effective.\\n\\n4. **Distance Metric Selection**:\\n   - The choice of distance metric can significantly affect DBSCAN\\'s performance in high-dimensional spaces. Some distance metrics, like Euclidean distance, may become less informative as the number of dimensions increases. Consider using more robust distance metrics designed for high-dimensional data, such as cosine similarity or Mahalanobis distance.\\n\\n5. **Data Preprocessing**:\\n   - Data preprocessing steps such as feature scaling, normalization, and outlier removal become crucial in high-dimensional spaces. Addressing outliers and ensuring that features have similar scales can improve the performance of DBSCAN.\\n\\n6. **Interpretability**:\\n   - Interpreting clusters in high-dimensional spaces can be challenging, as visualizing the clusters becomes difficult. The analysis and interpretation of clustering results may require specialized techniques or domain knowledge.\\n\\n7. **Computational Complexity**:\\n   - DBSCAN\\'s computational complexity can increase in high-dimensional spaces due to the need to compute distances between data points in all dimensions. Depending on the dataset\\'s size and dimensionality, this can lead to increased computation time and memory requirements.\\n\\nIn summary, while DBSCAN can be applied to high-dimensional feature spaces, it requires careful consideration of the challenges associated with high dimensionality. Parameter tuning, distance metric selection, dimension reduction, and data preprocessing are essential steps in making DBSCAN effective for high-dimensional data. It\\'s also important to evaluate the quality of clustering results and consider alternative clustering algorithms or techniques if DBSCAN does not perform well in a specific high-dimensional dataset.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q7. How does DBSCAN clustering handle clusters with varying densities?\n",
        "\n",
        "'''\n",
        "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is well-suited for handling clusters with varying densities in a dataset. In fact, one of the strengths of DBSCAN is its ability to identify clusters of different shapes and sizes, including clusters with varying densities. Here's how DBSCAN handles clusters with varying densities:\n",
        "\n",
        "1. **Density-Based Approach**:\n",
        "   - DBSCAN defines clusters based on the concept of density, which is the number of data points within a specified radius (ε) of a given data point. Clusters are formed around core points, which are data points that have at least MinPts (minimum points) neighbors within the ε distance.\n",
        "\n",
        "2. **Core Points and Border Points**:\n",
        "   - In regions of high data point density, many data points are close to each other and qualify as core points. These core points form the dense core of a cluster.\n",
        "   - In regions of lower density within the cluster, some data points may not have enough neighbors to be considered core points but are still within ε distance of core points. These data points are called border points and are part of the cluster.\n",
        "\n",
        "3. **Variable Cluster Densities**:\n",
        "   - DBSCAN naturally adapts to varying cluster densities. It identifies dense regions as clusters and allows the density to vary within clusters. In other words, DBSCAN doesn't require all parts of a cluster to have the same density.\n",
        "\n",
        "4. **Cluster Boundary Flexibility**:\n",
        "   - The boundary of a DBSCAN cluster can adapt to the varying density of the data points within the cluster. This means that the cluster boundary can be irregular and follow the shape of the denser region, allowing for more accurate representation of cluster boundaries in datasets with varying densities.\n",
        "\n",
        "5. **Noise Handling**:\n",
        "   - DBSCAN also effectively handles noise points, which are data points that do not belong to any cluster due to their isolation or low density. Noise points are treated as outliers and are not forced into any cluster.\n",
        "\n",
        "6. **Parameter Control**:\n",
        "   - The key parameters in DBSCAN, ε (epsilon) and MinPts, provide control over the sensitivity to density variations. Larger ε values allow for the inclusion of more distant points in a cluster, potentially merging nearby clusters with varying densities. Smaller ε values lead to stricter density requirements for cluster formation.\n",
        "\n",
        "In summary, DBSCAN's density-based clustering approach is particularly well-suited for datasets containing clusters with varying densities. It can automatically discover clusters with different shapes and sizes without the need for prior knowledge of the data distribution. This adaptability makes DBSCAN a powerful tool for a wide range of data clustering tasks, especially when dealing with complex and real-world datasets where clusters may have uneven or irregular densities.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "zie2GkNuyGFX",
        "outputId": "dbdc93db-22a6-4114-ee0f-904aa228c9d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nDBSCAN (Density-Based Spatial Clustering of Applications with Noise) is well-suited for handling clusters with varying densities in a dataset. In fact, one of the strengths of DBSCAN is its ability to identify clusters of different shapes and sizes, including clusters with varying densities. Here's how DBSCAN handles clusters with varying densities:\\n\\n1. **Density-Based Approach**:\\n   - DBSCAN defines clusters based on the concept of density, which is the number of data points within a specified radius (ε) of a given data point. Clusters are formed around core points, which are data points that have at least MinPts (minimum points) neighbors within the ε distance.\\n\\n2. **Core Points and Border Points**:\\n   - In regions of high data point density, many data points are close to each other and qualify as core points. These core points form the dense core of a cluster.\\n   - In regions of lower density within the cluster, some data points may not have enough neighbors to be considered core points but are still within ε distance of core points. These data points are called border points and are part of the cluster.\\n\\n3. **Variable Cluster Densities**:\\n   - DBSCAN naturally adapts to varying cluster densities. It identifies dense regions as clusters and allows the density to vary within clusters. In other words, DBSCAN doesn't require all parts of a cluster to have the same density.\\n\\n4. **Cluster Boundary Flexibility**:\\n   - The boundary of a DBSCAN cluster can adapt to the varying density of the data points within the cluster. This means that the cluster boundary can be irregular and follow the shape of the denser region, allowing for more accurate representation of cluster boundaries in datasets with varying densities.\\n\\n5. **Noise Handling**:\\n   - DBSCAN also effectively handles noise points, which are data points that do not belong to any cluster due to their isolation or low density. Noise points are treated as outliers and are not forced into any cluster.\\n\\n6. **Parameter Control**:\\n   - The key parameters in DBSCAN, ε (epsilon) and MinPts, provide control over the sensitivity to density variations. Larger ε values allow for the inclusion of more distant points in a cluster, potentially merging nearby clusters with varying densities. Smaller ε values lead to stricter density requirements for cluster formation.\\n\\nIn summary, DBSCAN's density-based clustering approach is particularly well-suited for datasets containing clusters with varying densities. It can automatically discover clusters with different shapes and sizes without the need for prior knowledge of the data distribution. This adaptability makes DBSCAN a powerful tool for a wide range of data clustering tasks, especially when dealing with complex and real-world datasets where clusters may have uneven or irregular densities.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q8. What are some common evaluation metrics used to assess the quality of DBSCAN clustering results?\n",
        "\n",
        "'''\n",
        "Evaluating the quality of DBSCAN (Density-Based Spatial Clustering of Applications with Noise) clustering results is essential to assess how well the algorithm has performed on a given dataset. Several evaluation metrics can be used to measure the quality of DBSCAN clustering results. The choice of metric depends on the specific characteristics of the data and the clustering goals. Here are some common evaluation metrics used for assessing DBSCAN clustering:\n",
        "\n",
        "1. **Silhouette Score**:\n",
        "   - The silhouette score measures the quality of clustering by considering the distance between data points within the same cluster (a) and the distance between data points in different clusters (b). The silhouette score ranges from -1 to 1, with higher values indicating better cluster separation and cohesion. A higher silhouette score implies that the clusters are well-defined and well-separated.\n",
        "\n",
        "2. **Davies-Bouldin Index**:\n",
        "   - The Davies-Bouldin index quantifies the average similarity between each cluster and its most similar cluster. Lower Davies-Bouldin index values indicate better clustering, with smaller inter-cluster similarity and greater intra-cluster similarity.\n",
        "\n",
        "3. **Calinski-Harabasz Index (Variance Ratio Criterion)**:\n",
        "   - The Calinski-Harabasz index, also known as the variance ratio criterion, measures the ratio of between-cluster variance to within-cluster variance. Higher values of this index suggest better separation between clusters.\n",
        "\n",
        "4. **Dunn Index**:\n",
        "   - The Dunn index evaluates clustering quality by comparing the minimum inter-cluster distance to the maximum intra-cluster distance. A higher Dunn index indicates better clustering, as it signifies tighter clusters and greater separation between clusters.\n",
        "\n",
        "5. **Adjusted Rand Index (ARI)**:\n",
        "   - ARI is a measure of the similarity between the ground truth (if available) and the clustering results. It accounts for random chance and adjusts the Rand Index. ARI values range from -1 to 1, where a higher value suggests better clustering results.\n",
        "\n",
        "6. **Adjusted Mutual Information (AMI)**:\n",
        "   - Similar to ARI, the adjusted mutual information measures the agreement between the ground truth and clustering results, accounting for random chance. Higher AMI values indicate better agreement between the true clusters and the identified clusters.\n",
        "\n",
        "7. **Homogeneity, Completeness, and V-Measure**:\n",
        "   - These three metrics (homogeneity, completeness, and V-measure) assess different aspects of clustering quality. Homogeneity measures how well each cluster contains only data points that belong to a single class. Completeness measures how well all data points of a class are assigned to the same cluster. The V-measure is the harmonic mean of homogeneity and completeness.\n",
        "\n",
        "8. **Contingency Table Metrics**:\n",
        "   - Metrics like purity, normalized mutual information (NMI), and Fowlkes-Mallows index are based on contingency tables and are used to compare clustering results to ground truth labels if available.\n",
        "\n",
        "9. **Visual Inspection**:\n",
        "   - Sometimes, visual inspection and exploration of clustering results through scatter plots, heatmaps, or other visualization techniques can provide insights into the quality of clusters and their separation.\n",
        "\n",
        "It's important to note that the choice of evaluation metric should be guided by the specific goals of the clustering task and the characteristics of the data. There is no one-size-fits-all metric, and different metrics may emphasize different aspects of clustering quality. Therefore, it is often advisable to use multiple metrics and visualizations to gain a comprehensive understanding of the clustering results. Additionally, in cases where ground truth labels are available, comparing clustering results to the ground truth can be informative.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "mX6VFRKUyOf2",
        "outputId": "93954c06-ed3e-413d-c2f1-bc28ba49cead"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nEvaluating the quality of DBSCAN (Density-Based Spatial Clustering of Applications with Noise) clustering results is essential to assess how well the algorithm has performed on a given dataset. Several evaluation metrics can be used to measure the quality of DBSCAN clustering results. The choice of metric depends on the specific characteristics of the data and the clustering goals. Here are some common evaluation metrics used for assessing DBSCAN clustering:\\n\\n1. **Silhouette Score**:\\n   - The silhouette score measures the quality of clustering by considering the distance between data points within the same cluster (a) and the distance between data points in different clusters (b). The silhouette score ranges from -1 to 1, with higher values indicating better cluster separation and cohesion. A higher silhouette score implies that the clusters are well-defined and well-separated.\\n\\n2. **Davies-Bouldin Index**:\\n   - The Davies-Bouldin index quantifies the average similarity between each cluster and its most similar cluster. Lower Davies-Bouldin index values indicate better clustering, with smaller inter-cluster similarity and greater intra-cluster similarity.\\n\\n3. **Calinski-Harabasz Index (Variance Ratio Criterion)**:\\n   - The Calinski-Harabasz index, also known as the variance ratio criterion, measures the ratio of between-cluster variance to within-cluster variance. Higher values of this index suggest better separation between clusters.\\n\\n4. **Dunn Index**:\\n   - The Dunn index evaluates clustering quality by comparing the minimum inter-cluster distance to the maximum intra-cluster distance. A higher Dunn index indicates better clustering, as it signifies tighter clusters and greater separation between clusters.\\n\\n5. **Adjusted Rand Index (ARI)**:\\n   - ARI is a measure of the similarity between the ground truth (if available) and the clustering results. It accounts for random chance and adjusts the Rand Index. ARI values range from -1 to 1, where a higher value suggests better clustering results.\\n\\n6. **Adjusted Mutual Information (AMI)**:\\n   - Similar to ARI, the adjusted mutual information measures the agreement between the ground truth and clustering results, accounting for random chance. Higher AMI values indicate better agreement between the true clusters and the identified clusters.\\n\\n7. **Homogeneity, Completeness, and V-Measure**:\\n   - These three metrics (homogeneity, completeness, and V-measure) assess different aspects of clustering quality. Homogeneity measures how well each cluster contains only data points that belong to a single class. Completeness measures how well all data points of a class are assigned to the same cluster. The V-measure is the harmonic mean of homogeneity and completeness.\\n\\n8. **Contingency Table Metrics**:\\n   - Metrics like purity, normalized mutual information (NMI), and Fowlkes-Mallows index are based on contingency tables and are used to compare clustering results to ground truth labels if available.\\n\\n9. **Visual Inspection**:\\n   - Sometimes, visual inspection and exploration of clustering results through scatter plots, heatmaps, or other visualization techniques can provide insights into the quality of clusters and their separation.\\n\\nIt's important to note that the choice of evaluation metric should be guided by the specific goals of the clustering task and the characteristics of the data. There is no one-size-fits-all metric, and different metrics may emphasize different aspects of clustering quality. Therefore, it is often advisable to use multiple metrics and visualizations to gain a comprehensive understanding of the clustering results. Additionally, in cases where ground truth labels are available, comparing clustering results to the ground truth can be informative.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q9. Can DBSCAN clustering be used for semi-supervised learning tasks?\n",
        "'''\n",
        "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is primarily an unsupervised clustering algorithm, meaning it does not rely on labeled data for training. However, it can be used in conjunction with semi-supervised learning techniques to perform certain semi-supervised tasks or to aid in the pre-processing of data for semi-supervised learning. Here's how DBSCAN can be related to semi-supervised learning:\n",
        "\n",
        "1. **Data Preprocessing**:\n",
        "   - DBSCAN can be used as a data pre-processing step in semi-supervised learning. By clustering unlabeled data points, you can identify potential clusters or groups of similar data points. This can help create \"pseudo-labels\" for the clusters, which can be used as additional information in semi-supervised algorithms.\n",
        "\n",
        "2. **Outlier Detection**:\n",
        "   - In semi-supervised learning, identifying and handling outliers is crucial. DBSCAN is effective at detecting outliers or noise points. You can use DBSCAN to label data points as either inliers or outliers, and then incorporate this information into a semi-supervised algorithm.\n",
        "\n",
        "3. **Feature Engineering**:\n",
        "   - DBSCAN's ability to discover clusters based on density can be used for feature engineering. Features extracted from clusters can be included in the feature set used for semi-supervised learning. This can help improve the representation of the data for subsequent classification or regression tasks.\n",
        "\n",
        "4. **Active Learning**:\n",
        "   - In some semi-supervised scenarios, active learning can be employed to select the most informative data points for labeling. DBSCAN can help identify clusters of data points that may contain valuable information for active learning strategies.\n",
        "\n",
        "5. **Anomaly Detection**:\n",
        "   - In certain semi-supervised applications, distinguishing between normal and anomalous data points is crucial. DBSCAN can assist in this aspect by classifying data points as inliers (normal) or outliers (anomalous), which can be used as labels or weights in a semi-supervised algorithm.\n",
        "\n",
        "6. **Handling Imbalanced Data**:\n",
        "   - In semi-supervised tasks with imbalanced data, DBSCAN's ability to uncover clusters of varying sizes and densities can help address the imbalance by focusing on minority clusters or outliers.\n",
        "\n",
        "While DBSCAN can be a valuable tool in semi-supervised learning scenarios, it's important to note that DBSCAN itself is an unsupervised algorithm and doesn't inherently provide class labels. The incorporation of DBSCAN into semi-supervised learning often requires additional steps, such as assigning labels to clusters or utilizing cluster information as auxiliary features. The effectiveness of this approach depends on the specific characteristics of the dataset and the goals of the semi-supervised learning task.'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "vIUUfVuyyZTm",
        "outputId": "bfa50972-fd43-42d7-967e-1b4b4f1df1aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nDBSCAN (Density-Based Spatial Clustering of Applications with Noise) is primarily an unsupervised clustering algorithm, meaning it does not rely on labeled data for training. However, it can be used in conjunction with semi-supervised learning techniques to perform certain semi-supervised tasks or to aid in the pre-processing of data for semi-supervised learning. Here\\'s how DBSCAN can be related to semi-supervised learning:\\n\\n1. **Data Preprocessing**:\\n   - DBSCAN can be used as a data pre-processing step in semi-supervised learning. By clustering unlabeled data points, you can identify potential clusters or groups of similar data points. This can help create \"pseudo-labels\" for the clusters, which can be used as additional information in semi-supervised algorithms.\\n\\n2. **Outlier Detection**:\\n   - In semi-supervised learning, identifying and handling outliers is crucial. DBSCAN is effective at detecting outliers or noise points. You can use DBSCAN to label data points as either inliers or outliers, and then incorporate this information into a semi-supervised algorithm.\\n\\n3. **Feature Engineering**:\\n   - DBSCAN\\'s ability to discover clusters based on density can be used for feature engineering. Features extracted from clusters can be included in the feature set used for semi-supervised learning. This can help improve the representation of the data for subsequent classification or regression tasks.\\n\\n4. **Active Learning**:\\n   - In some semi-supervised scenarios, active learning can be employed to select the most informative data points for labeling. DBSCAN can help identify clusters of data points that may contain valuable information for active learning strategies.\\n\\n5. **Anomaly Detection**:\\n   - In certain semi-supervised applications, distinguishing between normal and anomalous data points is crucial. DBSCAN can assist in this aspect by classifying data points as inliers (normal) or outliers (anomalous), which can be used as labels or weights in a semi-supervised algorithm.\\n\\n6. **Handling Imbalanced Data**:\\n   - In semi-supervised tasks with imbalanced data, DBSCAN\\'s ability to uncover clusters of varying sizes and densities can help address the imbalance by focusing on minority clusters or outliers.\\n\\nWhile DBSCAN can be a valuable tool in semi-supervised learning scenarios, it\\'s important to note that DBSCAN itself is an unsupervised algorithm and doesn\\'t inherently provide class labels. The incorporation of DBSCAN into semi-supervised learning often requires additional steps, such as assigning labels to clusters or utilizing cluster information as auxiliary features. The effectiveness of this approach depends on the specific characteristics of the dataset and the goals of the semi-supervised learning task.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q10. How does DBSCAN clustering handle datasets with noise or missing values?\n",
        "\n",
        "'''\n",
        "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) can handle datasets with noise and missing values to some extent, but its performance and behavior in such situations depend on various factors. Here's how DBSCAN deals with datasets containing noise or missing values:\n",
        "\n",
        "**Handling Noise**:\n",
        "\n",
        "1. **Noise Identification**:\n",
        "   - DBSCAN is designed to handle noise naturally. Noise points, which are data points that do not belong to any cluster due to their isolation or low local density, are explicitly identified and labeled as noise during the clustering process.\n",
        "\n",
        "2. **Robustness to Noise**:\n",
        "   - DBSCAN is robust to the presence of noise because it does not force data points into clusters if they do not meet the density criteria. Noise points are essentially left unclustered, allowing for the detection of meaningful clusters despite the presence of noisy data.\n",
        "\n",
        "3. **Parameter Tuning**:\n",
        "   - Parameter tuning, particularly the choice of ε (epsilon) and MinPts (minimum points), can influence DBSCAN's ability to detect noise. Careful selection of these parameters is essential, as setting ε too large may merge clusters and include noise, while setting it too small may label legitimate clusters as noise.\n",
        "\n",
        "**Handling Missing Values**:\n",
        "\n",
        "1. **Missing Value Handling**:\n",
        "   - DBSCAN, as a density-based clustering algorithm, assumes that each data point has a defined position in the feature space. If a data point has missing values for some features, it may pose challenges for distance calculations, as distances between data points are typically computed based on all available features.\n",
        "\n",
        "2. **Imputation**:\n",
        "   - To use DBSCAN with datasets containing missing values, you may need to perform imputation, which involves filling in or estimating missing values. Various imputation techniques, such as mean imputation, median imputation, or more sophisticated methods like k-nearest neighbors (KNN) imputation, can be applied to replace missing values.\n",
        "\n",
        "3. **Feature Selection**:\n",
        "   - If missing values affect a significant portion of your dataset or specific features are particularly prone to missing values, you may consider feature selection or feature engineering to reduce the impact of missing data on the clustering process.\n",
        "\n",
        "4. **Distance Metric Choice**:\n",
        "   - The choice of distance metric is crucial when dealing with missing values. Some distance metrics, such as the Mahalanobis distance, can handle missing values more effectively by taking into account the covariance structure of the available features.\n",
        "\n",
        "5. **Dimension Reduction**:\n",
        "   - Dimension reduction techniques like Principal Component Analysis (PCA) can be applied to reduce the dimensionality of the data while minimizing the impact of missing values. This can simplify distance calculations and make DBSCAN more manageable.\n",
        "\n",
        "6. **Cluster-Specific Imputation**:\n",
        "   - In some cases, you might choose to perform imputation within individual clusters based on available data within each cluster. This approach can be beneficial if the missingness of data is not uniform across the dataset.\n",
        "\n",
        "In summary, while DBSCAN can handle noise by explicitly identifying and labeling noise points, dealing with missing values in DBSCAN requires careful data preprocessing, imputation, and possibly feature engineering. The effectiveness of DBSCAN on datasets with missing values depends on the nature and extent of missingness, as well as the strategies used to address it.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "lLI7Ae-lym_u",
        "outputId": "a1784279-96a2-47b4-d133-ee0b4f2ed112"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nDBSCAN (Density-Based Spatial Clustering of Applications with Noise) can handle datasets with noise and missing values to some extent, but its performance and behavior in such situations depend on various factors. Here's how DBSCAN deals with datasets containing noise or missing values:\\n\\n**Handling Noise**:\\n\\n1. **Noise Identification**:\\n   - DBSCAN is designed to handle noise naturally. Noise points, which are data points that do not belong to any cluster due to their isolation or low local density, are explicitly identified and labeled as noise during the clustering process.\\n\\n2. **Robustness to Noise**:\\n   - DBSCAN is robust to the presence of noise because it does not force data points into clusters if they do not meet the density criteria. Noise points are essentially left unclustered, allowing for the detection of meaningful clusters despite the presence of noisy data.\\n\\n3. **Parameter Tuning**:\\n   - Parameter tuning, particularly the choice of ε (epsilon) and MinPts (minimum points), can influence DBSCAN's ability to detect noise. Careful selection of these parameters is essential, as setting ε too large may merge clusters and include noise, while setting it too small may label legitimate clusters as noise.\\n\\n**Handling Missing Values**:\\n\\n1. **Missing Value Handling**:\\n   - DBSCAN, as a density-based clustering algorithm, assumes that each data point has a defined position in the feature space. If a data point has missing values for some features, it may pose challenges for distance calculations, as distances between data points are typically computed based on all available features.\\n\\n2. **Imputation**:\\n   - To use DBSCAN with datasets containing missing values, you may need to perform imputation, which involves filling in or estimating missing values. Various imputation techniques, such as mean imputation, median imputation, or more sophisticated methods like k-nearest neighbors (KNN) imputation, can be applied to replace missing values.\\n\\n3. **Feature Selection**:\\n   - If missing values affect a significant portion of your dataset or specific features are particularly prone to missing values, you may consider feature selection or feature engineering to reduce the impact of missing data on the clustering process.\\n\\n4. **Distance Metric Choice**:\\n   - The choice of distance metric is crucial when dealing with missing values. Some distance metrics, such as the Mahalanobis distance, can handle missing values more effectively by taking into account the covariance structure of the available features.\\n\\n5. **Dimension Reduction**:\\n   - Dimension reduction techniques like Principal Component Analysis (PCA) can be applied to reduce the dimensionality of the data while minimizing the impact of missing values. This can simplify distance calculations and make DBSCAN more manageable.\\n\\n6. **Cluster-Specific Imputation**:\\n   - In some cases, you might choose to perform imputation within individual clusters based on available data within each cluster. This approach can be beneficial if the missingness of data is not uniform across the dataset.\\n\\nIn summary, while DBSCAN can handle noise by explicitly identifying and labeling noise points, dealing with missing values in DBSCAN requires careful data preprocessing, imputation, and possibly feature engineering. The effectiveness of DBSCAN on datasets with missing values depends on the nature and extent of missingness, as well as the strategies used to address it.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q11. Implement the DBSCAN algorithm using a python programming language, and apply it to a sample\n",
        "# dataset. Discuss the clustering results and interpret the meaning of the obtained clusters.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "# Generate a sample dataset (moons)\n",
        "X, _ = make_moons(n_samples=200, noise=0.05, random_state=42)\n",
        "\n",
        "# Instantiate and fit the DBSCAN model\n",
        "dbscan = DBSCAN(eps=0.3, min_samples=5)\n",
        "dbscan.fit(X)\n",
        "\n",
        "# Extract cluster labels (-1 represents noise)\n",
        "labels = dbscan.labels_\n",
        "\n",
        "# Number of clusters (ignoring noise points, labeled as -1)\n",
        "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "\n",
        "# Plot the data points with different colors for each cluster\n",
        "unique_labels = set(labels)\n",
        "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
        "\n",
        "for k, col in zip(unique_labels, colors):\n",
        "    if k == -1:\n",
        "        col = [0, 0, 0, 1]  # Black for noise points (label -1)\n",
        "\n",
        "    class_member_mask = (labels == k)\n",
        "    xy = X[class_member_mask]\n",
        "\n",
        "    plt.scatter(xy[:, 0], xy[:, 1], c=[col], label=f'Cluster {k}')\n",
        "\n",
        "plt.title(f'DBSCAN Clustering (Estimated {n_clusters} Clusters)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "6n2F6QYLzDGe",
        "outputId": "c2842c50-2222-4566-9b64-21c59aa959bd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}