{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
        "Q2. What are the different methods used for Web Scraping?\n",
        "Q3. What is Beautiful Soup? Why is it used?\n",
        "Q4. Why is flask used in this Web Scraping project?\n",
        "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "znYWgULakfGb",
        "outputId": "f43b911c-f797-4271-a3d7-6b2e1f1ecc94"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\\nQ2. What are the different methods used for Web Scraping?\\nQ3. What is Beautiful Soup? Why is it used?\\nQ4. Why is flask used in this Web Scraping project?\\nQ5. Write the names of AWS services used in this project. Also, explain the use of each service.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "rJ75UFxzkBNV",
        "outputId": "9e216e39-da6c-4662-d524-f96e0abee41a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"\\nQ1. Web scraping is the automated extraction of data from websites. It\\'s used to gather information, analyze trends, and support decision-making in various domains like e-commerce (price tracking), research (data collection), and finance (stock market data).\\n\\nQ2. Different web scraping methods include using libraries like BeautifulSoup and Scrapy, as well as tools like Selenium for dynamic websites. APIs and commercial scraping services are other methods.\\n\\nQ3. Beautiful Soup is a Python library for parsing HTML and XML documents. It\\'s used to extract data from web pages by navigating and searching the HTML structure, making web scraping easier and more efficient.\\n\\nQ4. Flask is used in this web scraping project to create a web application or API for users to interact with the scraped data. It provides a simple and lightweight framework for building web interfaces on top of the scraped data.\\n\\nQ5. AWS services used in this project could include Amazon EC2 (for hosting web scraping code), Amazon S3 (for storing scraped data), and Amazon RDS (for database management). EC2 provides computing power, S3 stores data, and RDS manages databases, enabling a scalable and reliable infrastructure for web scraping.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\"\"\"\"\n",
        "A1. Web scraping is the automated extraction of data from websites. It's used to gather information, analyze trends, and support decision-making in various domains like e-commerce (price tracking), research (data collection), and finance (stock market data).\n",
        "\n",
        "A2. Different web scraping methods include using libraries like BeautifulSoup and Scrapy, as well as tools like Selenium for dynamic websites. APIs and commercial scraping services are other methods.\n",
        "\n",
        "A3. Beautiful Soup is a Python library for parsing HTML and XML documents. It's used to extract data from web pages by navigating and searching the HTML structure, making web scraping easier and more efficient.\n",
        "\n",
        "A4. Flask is used in this web scraping project to create a web application or API for users to interact with the scraped data. It provides a simple and lightweight framework for building web interfaces on top of the scraped data.\n",
        "\n",
        "A5. AWS services used in this project could include Amazon EC2 (for hosting web scraping code), Amazon S3 (for storing scraped data), and Amazon RDS (for database management). EC2 provides computing power, S3 stores data, and RDS manages databases, enabling a scalable and reliable infrastructure for web scraping.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pR--HHrRkp-1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}